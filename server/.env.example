# EASE Server Configuration
# Copy this to .env and adjust as needed

# ============================================
# Model Configuration
# ============================================

# Base Stable Diffusion model (HuggingFace ID or local path)
# Options: "SimianLuo/LCM_Dreamshaper_v7", "runwayml/stable-diffusion-v1-5", "Lykon/dreamshaper-8"
EASE_MODEL=Lykon/dreamshaper-8

# Resolution (lower = faster, less VRAM)
EASE_WIDTH=512
EASE_HEIGHT=512

# Device and precision
EASE_DEVICE=cuda
# Data type: float16, float32, or bfloat16
EASE_DTYPE=float16

# ============================================
# Generation Defaults
# ============================================

# Number of denoising steps (lower = faster)
# Note: With hyper-sd, this should match EASE_HYPER_SD_STEPS
EASE_STEPS=4

# CFG scale (guidance strength, 0 for SD-Turbo)
EASE_CFG_SCALE=0.0

# Target frames per second
EASE_TARGET_FPS=20

# ============================================
# Feature Toggles (~5.5GB VRAM with defaults)
# ============================================

# TensorRT acceleration (requires additional setup)
EASE_USE_TENSORRT=false

# Compile UNet with torch.compile for faster inference
EASE_COMPILE_UNET=false

# ControlNet pose guidance (+~1GB VRAM)
# NOTE: Requires SD 1.5 base model, not SD-Turbo
EASE_USE_CONTROLNET=false

# Lyrics detection with Whisper (+~2GB VRAM)
EASE_LYRICS=false

# NSFW filter - uses safety checker with previous-frame fallback
# When enabled, inappropriate images are replaced with the last safe frame
# instead of showing black. Adds slight performance overhead (~20ms/frame).
EASE_NSFW_FILTER=false

# ============================================
# Server Settings
# ============================================

EASE_HOST=0.0.0.0
EASE_PORT=8765

# CORS allowed origins (comma-separated in actual config, JSON array here for reference)
# Default: ["http://localhost:5173", "http://localhost:3000"]
# EASE_CORS_ORIGINS=["http://localhost:5173", "http://localhost:3000"]

# ============================================
# Generator Backend
# ============================================

# Generator backend: "audio_reactive" (default), "stream_diffusion", "flux_klein"
# - audio_reactive: SD 1.5 + LCM optimized for audio reactivity (~10-15 FPS)
#   Capabilities: controlnet, lora, fast response to audio changes
# - stream_diffusion: SD 1.5 + StreamDiffusion for real-time (~15-20 FPS)
#   Capabilities: controlnet, lora, taesd, temporal_coherence, acceleration
# - flux_klein: FLUX.2 [klein] 4B for high quality (~1-3 FPS)
#   Capabilities: prompt_modulation (audio-reactive prompt enhancement)
#
# NOTE: Backend can also be switched at runtime from the UI!
# The UI provides a backend selector when connected to the server.
# Switching backends will stop generation, clean up VRAM, and reinitialize.
EASE_GENERATOR_BACKEND=audio_reactive

# ============================================
# FLUX.2 [klein] Backend Settings
# ============================================
# These settings only apply when EASE_GENERATOR_BACKEND=flux_klein
#
# Performance benchmarks on RTX 4090 at 512x512:
#   Baseline (CPU offload):     ~8.5s/frame  (0.1 FPS)
#   + torch.compile:            ~0.6s/frame  (1.7 FPS)  - 14x faster
#   + prompt caching:           ~5.0s/frame  (0.2 FPS)  - saves encoding time
#   + both optimizations:       ~0.3s/frame  (3.1 FPS)  - 26x faster

# Precision mode: bf16 (fp8/nvfp4 not yet supported)
# - bf16: Full precision bfloat16 (best quality, requires ~12GB VRAM)
# - fp8/nvfp4: NOT YET SUPPORTED - will fall back to bf16
#   (BFL's quantized models require manual weight loading)
# For memory savings, use EASE_FLUX_CPU_OFFLOAD=true instead
EASE_FLUX_PRECISION=bf16

# Override model ID (leave empty to auto-select based on precision)
EASE_FLUX_MODEL_ID=

# Enable sequential CPU offload for memory efficiency
# Recommended for GPUs with <16GB VRAM
# NOTE: Disable when using EASE_FLUX_COMPILE=true
EASE_FLUX_CPU_OFFLOAD=true

# Number of inference steps (FLUX.2 klein is optimized for 4 steps)
EASE_FLUX_INFERENCE_STEPS=4

# Guidance scale (FLUX.2 Klein uses 1.0)
EASE_FLUX_GUIDANCE_SCALE=1.0

# torch.compile optimization (14x speedup after warmup)
# Requires ~17GB VRAM, incompatible with CPU offload
# First generation is slow (~18s) due to compilation, then ~0.6s/frame
EASE_FLUX_COMPILE=false

# Cache text encoder outputs (prompt embeddings)
# Speeds up repeated generations with same prompt (~2x faster)
# Automatically enabled, disable only for debugging
EASE_FLUX_CACHE_PROMPT=true

# ============================================
# Acceleration Method
# ============================================

# Acceleration LoRA: "lcm", "hyper-sd", or "none"
# - lcm: LCM-LoRA with LCMScheduler (default, proven stable, 4-6 steps)
# - hyper-sd: ByteDance Hyper-SD with TCDScheduler (1-2 step generation)
# - none: No acceleration LoRA, standard scheduler
EASE_ACCELERATION=lcm

# Hyper-SD specific settings (only used when EASE_ACCELERATION=hyper-sd)
# Step variant: 1, 2, 4, or 8 (must match the LoRA variant)
EASE_HYPER_SD_STEPS=1
# LoRA fusion scale (0.125 recommended, much lower than LCM's 1.0)
EASE_HYPER_SD_LORA_SCALE=0.125
# Eta/stochasticity: 1.0 for 1-step, 0.3-0.5 for multi-step
EASE_HYPER_SD_ETA=1.0

# ============================================
# TAESD Settings (Tiny AutoEncoder)
# ============================================

# TAESD provides 100x faster decode but may have scaling issues
EASE_USE_TAESD=false
# Default TAESD model for SD 1.5
EASE_TAESD_MODEL=madebyollin/taesd
# TAESD model for SDXL
EASE_TAESD_SDXL_MODEL=madebyollin/taesdxl

# ============================================
# StreamDiffusion Optimizations
# ============================================

# Enable Stream Batch (1.5x speedup)
EASE_STREAM_BATCH=true

# Enable Residual CFG (2x speedup)
EASE_RESIDUAL_CFG=true

# Stochastic Similarity Filter (skip redundant frames)
EASE_SIMILARITY_FILTER=true
# Threshold for skipping frames (0.0-1.0)
EASE_SIMILARITY_THRESHOLD=0.98

# t_index_list controls which denoising steps to use
# [0, 16, 32, 45] works for both txt2img and img2img
# Later steps like [32, 45] only work for img2img
# EASE_T_INDEX_LIST=[0, 16, 32, 45]

# ============================================
# TensorRT Settings
# ============================================

# Cache directory for TensorRT engines
EASE_TENSORRT_CACHE_DIR=.tensorrt_cache

# Maximum batch size for TensorRT
EASE_TENSORRT_MAX_BATCH_SIZE=2

# Use FP16 precision for TensorRT
EASE_TENSORRT_USE_FP16=true

# ============================================
# Temporal Coherence
# ============================================

# Latent blending for frame-to-frame consistency
# NOTE: Currently DISABLED by default - broken with ControlNet/diffusers path
# (latent history only tracked in StreamDiffusion/TAESD paths)
EASE_LATENT_BLENDING=false

# Crossfeed settings for temporal consistency
EASE_CROSSFEED_POWER=0.3
EASE_CROSSFEED_RANGE=0.4
EASE_CROSSFEED_DECAY=0.4

# ============================================
# ControlNet Settings
# ============================================

# ControlNet pose guidance weight (0.0-1.0)
EASE_CONTROLNET_POSE_WEIGHT=0.8

# ControlNet lineart weight (0.0-1.0)
EASE_CONTROLNET_LINEART_WEIGHT=0.3

# ============================================
# IP-Adapter Settings
# ============================================

# Enable IP-Adapter for image-guided generation
EASE_USE_IP_ADAPTER=false

# IP-Adapter influence scale (0.0-1.0)
EASE_IP_ADAPTER_SCALE=0.6

# ============================================
# LoRA Settings
# ============================================

# Base directory for LoRA files
EASE_LORA_DIR=./loras

# Default LoRAs to load (JSON array)
# Format: [{"path": "style.safetensors", "weight": 0.8}]
# EASE_DEFAULT_LORAS=[]

# ============================================
# Frame Encoding
# ============================================

# JPEG quality for frame encoding (1-100)
EASE_JPEG_QUALITY=85

# ============================================
# Lyric Detection
# ============================================

# Lyric provider: "whisper", "hybrid", or "none"
# - whisper: Fast-whisper transcription (general ASR)
# - hybrid: Fingerprint matching + whisper fallback
# - none: Disable lyrics
EASE_LYRIC_PROVIDER=whisper

# Whisper model size
# Recommended: large-v3-turbo (6x faster than large, similar accuracy)
# Alternatives: large-v2 (best English), medium, small, tiny
EASE_LYRIC_MODEL_SIZE=large-v3-turbo

# Device for Whisper (cuda or cpu - use cpu to offload from GPU)
EASE_LYRIC_DEVICE=cuda

# Compute type: float16, int8, float32
EASE_LYRIC_COMPUTE_TYPE=float16

# Seconds between transcription runs
EASE_LYRIC_TRANSCRIBE_INTERVAL=1.0

# Rolling audio buffer in seconds (larger = more context, better accuracy)
EASE_LYRIC_BUFFER_SECONDS=5.0

# Beam size for Whisper (1 = greedy/faster, 5 = beam search/better)
EASE_LYRIC_BEAM_SIZE=5

# Initial prompt to hint context to Whisper
EASE_LYRIC_INITIAL_PROMPT=Song lyrics, singing vocals, English

# Filter words to exclude from transcription (JSON array)
# EASE_LYRIC_FILTER_WORDS=["lyrics", "singing", "music", "song", "vocal", "vocals", "english", "subscribe", "thank you for watching"]

# ============================================
# Vocal Separation (Demucs)
# ============================================

# Use Demucs to isolate vocals before transcription
EASE_LYRIC_VOCAL_SEPARATION=true

# Demucs model: htdemucs (fast), htdemucs_ft (better quality), mdx_extra (best)
EASE_LYRIC_DEMUCS_MODEL=htdemucs_ft

# Device for Demucs (cuda or cpu - use cpu to avoid GPU contention)
EASE_LYRIC_DEMUCS_DEVICE=cuda

# ============================================
# Audio Fingerprinting
# ============================================

# Enable audio fingerprinting for known song detection
EASE_FINGERPRINT_ENABLED=true

# Duration to fingerprint at session start (seconds)
EASE_FINGERPRINT_DURATION_SECONDS=15.0

# Path to lyrics database
EASE_FINGERPRINT_DB_PATH=./lyrics_db.sqlite

# ============================================
# Lyric Scheduling
# ============================================

# Align lyric changes to beat boundaries
EASE_LYRIC_BEAT_ALIGNED=true

# Delay lyric changes by N beats (perceptual masking)
EASE_LYRIC_BEAT_DELAY=2

# Enable VAD filtering (disable for music with heavy instrumentals)
EASE_LYRIC_VAD_FILTER=true

# VAD threshold (lower = more sensitive, good for music vocals)
EASE_LYRIC_VAD_THRESHOLD=0.3

# ============================================
# Silence Detection (Auto Song Change)
# ============================================

# Auto-detect song changes via silence gaps
EASE_SILENCE_DETECTION_ENABLED=true

# RMS threshold below which audio is considered silence (0-1)
EASE_SILENCE_THRESHOLD=0.02

# How long silence must last to trigger song change (seconds)
EASE_SILENCE_DURATION_SECONDS=1.0

# Minimum time between auto-resets to prevent rapid triggers (seconds)
EASE_SILENCE_COOLDOWN_SECONDS=3.0

# ============================================
# Logging Configuration
# ============================================

# Root log level (DEBUG, INFO, WARNING, ERROR)
EASE_LOG_LEVEL=INFO

# Module-specific log levels (set to DEBUG to troubleshoot specific areas)
# Generation timing (very verbose at DEBUG)
EASE_LOG_LEVEL_GENERATION=WARNING
# High-level generation events
EASE_LOG_LEVEL_PIPELINE=INFO
# Lyric detection/transcription
EASE_LOG_LEVEL_LYRICS=INFO
# WebSocket handling
EASE_LOG_LEVEL_SERVER=INFO
